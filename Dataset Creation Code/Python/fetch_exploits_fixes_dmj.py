#!/usr/bin/env python3
r"""
fetch_exploits_fixes_hardcoded_v3.py (FIXED)

This version uses the NVD API 2.0, which is more reliable and
provides tagged references for exploits and fixes.

Dependencies:
    pip install requests

API Key:
    You MUST set an NVD_API_KEY environment variable.
    Get one here: https://nvd.nist.gov/developers/request-an-api-key
"""
from dotenv import load_dotenv
load_dotenv()
import os
import json
import time
import logging
import re
from urllib.parse import quote_plus
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# ------- CONFIG -------
OUTPUT_DIR = r"C:\Users\Demo_\Downloads\armoureye\Datasets"
# Edit these INPUT paths if needed
DVWA_CVES = r"C:\Windows\System32\dvwa_cves.json"
JUICE_CVES = r"C:\Windows\System32\juice_cves.json"
METASPLOITABLE_CVES = r"C:\Windows\System32\metasploitable_cves.json"

logging.basicConfig(level=logging.INFO, format="%(message)s")
USER_AGENT = "fetch-exploits-fixes/2.0"
# NVD API 2.0 Endpoint
NVD_API_BASE = "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId="
MAX_WORKERS = 5
# NVD public API rate limit is 5 requests per 30s without a key.
# With a key, it's 50 requests per 30s. We sleep 0.7s to be safe.
NVD_SLEEP = 0.7

os.makedirs(OUTPUT_DIR, exist_ok=True)


def load_json(path):
    """Loads a JSON list or a JSON-Lines file."""
    with open(path, "r", encoding="utf-8-sig") as f:
        content = f.read()
    try:
        # Try parsing as a single JSON list
        data = json.loads(content)
        return data if isinstance(data, list) else [data]
    except json.JSONDecodeError:
        # If that fails, try parsing as JSON-Lines
        return [json.loads(line) for line in content.splitlines() if line.strip()]


def nvd_query(cve):
    """Queries the NVD API 2.0 for a single CVE."""
    headers = {"User-Agent": USER_AGENT}
    api_key = os.getenv("NVD_API_KEY")
    if api_key:
        headers["apiKey"] = api_key
    
    try:
        r = requests.get(NVD_API_BASE + cve, headers=headers, timeout=15)
        if r.status_code == 200:
            return r.json()
        else:
            logging.warning(f"NVD query for {cve} failed with status: {r.status_code}")
            return None
    except requests.RequestException as e:
        logging.error(f"NVD request for {cve} failed: {e}")
        return None


def parse_nvd_2_0(nj):
    """Parses the NVD 2.0 JSON response."""
    if not nj or not nj.get("vulnerabilities"):
        return {}

    try:
        cve_item = nj["vulnerabilities"][0]["cve"]
        cve_id = cve_item.get("id")
        
        # Get description
        description = ""
        for desc in cve_item.get("descriptions", []):
            if desc.get("lang") == "en":
                description = desc.get("value")
                break
        
        # Get CVSS score (prefer v3.1, fallback to v3.0, then v2)
        cvss = None
        if "cvssMetricV31" in cve_item.get("metrics", {}):
            cvss = cve_item["metrics"]["cvssMetricV31"][0]["cvssData"]["baseScore"]
        elif "cvssMetricV30" in cve_item.get("metrics", {}):
            cvss = cve_item["metrics"]["cvssMetricV30"][0]["cvssData"]["baseScore"]
        elif "cvssMetricV2" in cve_item.get("metrics", {}):
            cvss = cve_item["metrics"]["cvssMetricV2"][0]["cvssData"]["baseScore"]

        # Get all references
        references = cve_item.get("references", [])
        return {"title": cve_id, "description": description, "cvss": cvss, "references": references}
    
    except (IndexError, KeyError, TypeError) as e:
        logging.error(f"Failed to parse NVD response for {cve_id}: {e}")
        return {}


def find_links_from_refs(refs, tags_to_find):
    """Extracts URLs from NVD references based on their tags."""
    links = []
    seen = set()
    for ref in refs or []:
        url = ref.get("url")
        if not url or url in seen:
            continue
        
        ref_tags = set(ref.get("tags", []))
        if any(tag in ref_tags for tag in tags_to_find):
            links.append({"source": "nvd-ref", "url": url, "tags": ref.get("tags", [])})
            seen.add(url)
    return links


def enrich_entry(entry):
    """Enriches a single CVE entry with data from NVD."""
    cve = (entry.get("cve_id") or entry.get("CVE") or "").strip().upper()
    
    out = {
        "cve_id": cve,
        "package": entry.get("package"),
        "installed_version": entry.get("version"), # Renamed for clarity
        "severity": entry.get("severity"),
        "title": entry.get("title"), # Keep original title as fallback
        "description": entry.get("description"), # Keep original description
        "cvss": None,
        "exploits": [],
        "fixes": []
    }
    
    if not cve:
        logging.warning("Skipping entry with no cve_id")
        return out

    nvd_data = nvd_query(cve)
    parsed = parse_nvd_2_0(nvd_data)
    
    if parsed:
        out["title"] = parsed.get("title") or out["title"]
        out["description"] = parsed.get("description") or out["description"]
        out["cvss"] = parsed.get("cvss") or out["cvss"]
        
        # Use NVD tags to find exploits and fixes reliably
        all_refs = parsed.get("references", [])
        out["exploits"] = find_links_from_refs(all_refs, ["Exploit"])
        out["fixes"] = find_links_from_refs(all_refs, ["Patch", "Vendor Advisory", "Mitigation"])

    # This sleep is critical to respect NVD API rate limits
    time.sleep(NVD_SLEEP)
    return out


def process_file(inp):
    """Loads, processes, and saves data for one input file."""
    try:
        data = load_json(inp)
    except Exception as e:
        logging.error(f"Failed to load or parse {inp}: {e}")
        return 0, 0, 0
        
    logging.info(f"Processing {len(data)} entries from {inp}")
    enriched = []
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futs = {executor.submit(enrich_entry, e): e for e in data}
        for f in as_completed(futs):
            try:
                result = f.result()
                if result:
                    enriched.append(result)
            except Exception as exx:
                logging.error(f"An entry failed to process: {exx}")

    # Prepare output paths
    base = os.path.splitext(os.path.basename(inp))[0]
    enriched_out = os.path.join(OUTPUT_DIR, f"{base}_enriched.jsonl")
    exploits_out = os.path.join(OUTPUT_DIR, f"{base}_exploits.jsonl")
    fixes_out = os.path.join(OUTPUT_DIR, f"{base}_fixes.jsonl")

    # Write output files
    with open(enriched_out, "w", encoding="utf8") as fh:
        for item in enriched:
            fh.write(json.dumps(item, ensure_ascii=False) + "\n")

    with open(exploits_out, "w", encoding="utf8") as fe:
        for it in enriched:
            if it.get("exploits"):
                rec = {"cve_id": it.get("cve_id"), "exploits": it.get("exploits", [])}
                fe.write(json.dumps(rec, ensure_ascii=False) + "\n")

    with open(fixes_out, "w", encoding="utf8") as ff:
        for it in enriched:
            if it.get("fixes"):
                rec = {"cve_id": it.get("cve_id"), "fixes": it.get("fixes", [])}
                ff.write(json.dumps(rec, ensure_ascii=False) + "\n")

    # --- SUMMARY ---
    total = len(enriched)
    exploits_count = sum(1 for it in enriched if it.get("exploits"))
    fixes_count = sum(1 for it in enriched if it.get("fixes"))
    
    logging.info(f"Summary for {inp}: total={total}, with_exploits={exploits_count}, with_fixes={fixes_count}")
    
    # Sort by those with exploits first, then fixes
    def match_score(it):
        return (1 if it.get("exploits") else 0) * 2 + (1 if it.get("fixes") else 0)
        
    top = sorted(enriched, key=match_score, reverse=True)[:10]
    
    logging.info("Top matched CVEs (up to 10):")
    for t in top:
        if match_score(t) > 0: # Only show ones we found data for
            logging.info(f"  {t['cve_id']:<18} exploits={len(t.get('exploits') or [])} fixes={len(t.get('fixes') or [])}")
            
    logging.info(f"Wrote: {enriched_out}, {exploits_out}, {fixes_out}")
    return total, exploits_count, fixes_count


# --- Main execution ---
if __name__ == "__main__":
    files = [DVWA_CVES, JUICE_CVES, METASPLOITABLE_CVES]
    overall_total = 0
    overall_ex = 0
    overall_fx = 0

    if not os.getenv("NVD_API_KEY"):
        logging.warning("="*50)
        logging.warning("WARNING: NVD_API_KEY environment variable not set.")
        logging.warning("Script will be EXTREMELY slow and likely fail.")
        logging.warning("Get a key from: https://nvd.nist.gov/developers/request-an-api-key")
        logging.warning("="*50)
        time.sleep(5) # Give user time to see warning

    for f in files:
        if not os.path.isfile(f):
            logging.info(f"Skipping missing file: {f}")
            continue
        t, ex, fx = process_file(f)
        overall_total += t
        overall_ex += ex
        overall_fx += fx
        logging.info("-" * 20)

    logging.info(f"\nOVERALL SUMMARY: total_cves={overall_total}, with_exploits={overall_ex}, with_fixes={overall_fx}")