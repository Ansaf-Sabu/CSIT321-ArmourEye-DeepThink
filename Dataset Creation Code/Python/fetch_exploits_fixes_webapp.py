import os
import json
import time
import logging
import requests
from tqdm import tqdm
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- Config ---
load_dotenv()  # Load the .env file (NVD_API_KEY)

DATASET_DIR = r"C:\Users\Demo_\Downloads\armoureye\Datasets"
# 1. This is your new input file
CVE_INPUT_FILE = os.path.join(DATASET_DIR, "combined_cve_details_webapp.json")
# 2. This will be your final output file for fine-tuning
FINAL_OUTPUT_FILE = os.path.join(DATASET_DIR, "final_enriched_dataset.jsonl")

# NVD API 2.0 Endpoint
NVD_API_BASE = "https://services.nvd.nist.gov/rest/json/cves/2.0?cveId="
USER_AGENT = "fetch-exploits-fixes/3.0"
MAX_WORKERS = 5  # Number of parallel threads to fetch data
NVD_SLEEP = 0.7  # Sleep time (in seconds) between requests *per thread*

logging.basicConfig(level=logging.INFO, format="%(message)s")

# --- NVD API Functions (from previous script) ---

def nvd_query(cve_id):
    """Queries the NVD API 2.0 for a single CVE."""
    headers = {"User-Agent": USER_AGENT}
    api_key = os.getenv("NVD_API_KEY")
    if api_key:
        headers["apiKey"] = api_key
    
    try:
        r = requests.get(NVD_API_BASE + cve_id, headers=headers, timeout=15)
        if r.status_code == 200:
            return r.json()
        elif r.status_code == 404:
            logging.warning(f"NVD query for {cve_id} failed: Not Found (404)")
        else:
            logging.warning(f"NVD query for {cve_id} failed with status: {r.status_code}")
        return None
    except requests.RequestException as e:
        logging.error(f"NVD request for {cve_id} failed: {e}")
        return None

def parse_nvd_2_0(nvd_json):
    """Parses the NVD 2.0 JSON response to get references."""
    if not nvd_json or not nvd_json.get("vulnerabilities"):
        return []
    try:
        cve_item = nvd_json["vulnerabilities"][0]["cve"]
        return cve_item.get("references", [])
    except (IndexError, KeyError, TypeError):
        return []

def find_links_from_refs(refs, tags_to_find):
    """Extracts URLs from NVD references based on their tags."""
    links = []
    seen = set()
    for ref in refs or []:
        url = ref.get("url")
        if not url or url in seen:
            continue
        
        ref_tags = set(ref.get("tags", []))
        if any(tag in ref_tags for tag in tags_to_find):
            links.append({"source": "nvd-ref", "url": url, "tags": list(ref_tags)})
            seen.add(url)
    return links

def enrich_cve_entry(cve_entry):
    """Takes a single CVE entry and adds exploits/fixes to it."""
    cve_id = cve_entry.get("cve_id")
    
    # Initialize keys
    cve_entry["exploits"] = []
    cve_entry["fixes"] = []
    
    # Skip if no CVE ID or if it's not a standard CVE (like GHSA)
    if not cve_id or not cve_id.startswith("CVE-"):
        return cve_entry

    nvd_data = nvd_query(cve_id)
    all_refs = parse_nvd_2_0(nvd_data)
    
    if all_refs:
        cve_entry["exploits"] = find_links_from_refs(all_refs, ["Exploit"])
        cve_entry["fixes"] = find_links_from_refs(all_refs, ["Patch", "Vendor Advisory", "Mitigation"])

    # This sleep is critical to respect NVD API rate limits
    time.sleep(NVD_SLEEP)
    return cve_entry

# --- Main Execution ---
if __name__ == "__main__":
    if not os.getenv("NVD_API_KEY"):
        logging.warning("="*50)
        logging.warning("WARNING: NVD_API_KEY environment variable not set.")
        logging.warning("Script will be EXTREMELY slow and likely fail.")
        logging.warning("="*50)
        time.sleep(5)
        
    logging.info(f"Loading CVEs from {CVE_INPUT_FILE}...")
    try:
        with open(CVE_INPUT_FILE, 'r', encoding='utf-8') as f:
            cve_list = json.load(f)  # Load the entire list from the .json file
    except Exception as e:
        logging.error(f"Failed to load {CVE_INPUT_FILE}: {e}")
        exit()

    logging.info(f"Loaded {len(cve_list)} CVE records. Starting enrichment...")
    
    final_enriched_data = []
    
    # Use ThreadPoolExecutor to run fetches in parallel
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Wrap with tqdm for a progress bar
        futs = {executor.submit(enrich_cve_entry, entry): entry for entry in cve_list}
        for future in tqdm(as_completed(futs), total=len(cve_list), desc="Enriching CVEs"):
            try:
                result = future.result()
                if result:
                    final_enriched_data.append(result)
            except Exception as e:
                logging.error(f"An entry failed to process: {e}")

    logging.info(f"Enrichment complete. Writing {len(final_enriched_data)} records to {FINAL_OUTPUT_FILE}...")
    
    # Write the final output as JSON-Lines (one JSON object per line)
    try:
        with open(FINAL_OUTPUT_FILE, 'w', encoding='utf-8') as f:
            for entry in final_enriched_data:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        
        logging.info(f"\nâœ… Successfully wrote enriched data to {FINAL_OUTPUT_FILE}")
    except Exception as e:
        logging.error(f"Failed to write final output file: {e}")

    logging.info("All done.")